{
  "metadata": {
    "name": "test",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nimport sys\nfrom operator import add\nfrom pyspark import SparkContext\nfrom csv import reader"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\ndataset1 \u003d sc.textFile(\"hdfs:/user/CS-GY-6513/project_data/data-cityofnewyork-us.ye3c-m4ga.csv\").mapPartitions(lambda x: reader(x))\ndataset2 \u003d sc.textFile(\"hdfs:/user/CS-GY-6513/project_data/data-cityofnewyork-us.423i-ukqr.csv\").mapPartitions(lambda x: reader(x))\ndataset3 \u003d sc.textFile(\"hdfs:/user/CS-GY-6513/project_data/data-cityofnewyork-us.gzfs-3h4m.csv\").mapPartitions(lambda x: reader(x))\ndataset4 \u003d sc.textFile(\"hdfs:/user/CS-GY-6513/project_data/data-cityofnewyork-us.mdcw-n682.csv\").mapPartitions(lambda x: reader(x))\ndataset5 \u003d sc.textFile(\"hdfs:/user/CS-GY-6513/project_data/data-cityofnewyork-us.k397-673e.csv\").mapPartitions(lambda x: reader(x))\ndataset6 \u003d sc.textFile(\"hdfs:/user/CS-GY-6513/project_data/data-cityofnewyork-us.mwzb-yiwb.csv\").mapPartitions(lambda x: reader(x))\ndataset7 \u003d sc.textFile(\"hdfs:/user/CS-GY-6513/project_data/data-cityofnewyork-us.a9md-ynri.csv\").mapPartitions(lambda x: reader(x))\ndataset8 \u003d sc.textFile(\"hdfs:/user/CS-GY-6513/project_data/data-cityofnewyork-us.vx8i-nprf.csv\").mapPartitions(lambda x: reader(x))\ndataset9 \u003d sc.textFile(\"hdfs:/user/CS-GY-6513/project_data/data-cityofnewyork-us.xrwg-eczf.csv\").mapPartitions(lambda x: reader(x))\ndataset10 \u003d sc.textFile(\"hdfs:/user/CS-GY-6513/project_data/data-cityofnewyork-us.qbjq-atxv.csv\").mapPartitions(lambda x: reader(x))"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nprint(dataset1.first())\nprint(dataset2.first())\nprint(dataset3.first())\nprint(dataset4.first())\nprint(dataset5.first())\nprint(dataset6.first())\nprint(dataset7.first())\nprint(dataset8.first())\nprint(dataset9.first())\nprint(dataset10.first())"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\ndef toUpperCase(x):\n    if x !\u003d \u0027\u0027:\n        return x.upper();\n    else:\n        return \" \""
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\ndef elimateBlank(x):\n    x \u003d x.strip()\n    return x;"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\ndef identical(x):\n    if len(x.split(\u0027 \u0027)) \u003d\u003d 3 and x.split(\u0027 \u0027)[0] \u003d\u003d \u0027COMMUNITY\u0027 and x.split(\u0027 \u0027)[1] \u003d\u003d \u0027BOARD\u0027:\n        number \u003d x.split(\u0027.\u0027)[1].split(\u0027-\u0027)[0]\n        reg \u003d x.split(\u0027-\u0027)[1]\n        print(len(reg))\n        reg \u003d reg[0:4]\n        print(reg)\n        if reg \u003d\u003d \u0027QUEE\u0027:\n            c_reg \u003d \u0027QUEENS\u0027\n            x \u003d c_reg + \u0027 \u0027 + \u0027COMMUNITY BOARD #\u0027 + number\n        if reg \u003d\u003d \u0027BROO\u0027:\n            c_reg \u003d \u0027BROOKLYN\u0027\n            x \u003d c_reg + \u0027 \u0027 + \u0027COMMUNITY BOARD #\u0027 + number\n        if reg \u003d\u003d \u0027BRON\u0027:\n            c_reg \u003d \u0027BRONX\u0027\n            x \u003d c_reg + \u0027 \u0027 + \u0027COMMUNITY BOARD #\u0027 + number\n        if reg \u003d\u003d \u0027MANH\u0027:\n            c_reg \u003d \u0027MANHATTAN\u0027\n            x \u003d c_reg + \u0027 \u0027 + \u0027COMMUNITY BOARD #\u0027 + number\n        if reg \u003d\u003d \u0027RICH\u0027:\n            c_reg \u003d \u0027RICHMOND\u0027\n            x \u003d c_reg + \u0027 \u0027 + \u0027COMMUNITY BOARD #\u0027 + number\n    return x\n\ntest \u003d identical(\"COMMUNITY BOARD NO.8-MANHA\")\nprint(test)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\ndef completeTheDatas(x):\n    if x \u003d\u003d \u0027DEPARTMENT OF CITYWIDE ADM\u0027:\n        x \u003d \u0027DEPARTMENT OF CITYWIDE ADMINISTRATIVE SERVICES\u0027\n    if x \u003d\u003d \u0027HRA/DEPARTMENT OF SOCIAL S\u0027:\n        x \u003d \u0027HRA/DEPARTMENT OF SOCIAL SERVICES\u0027\n    if x \u003d\u003d \u0027CUNY QUEENSBOROUGH COMMUNI\u0027:\n        x \u003d \u0027CUNY QUEENSBOROUGH COMMUNITY\u0027\n    if x \u003d\u003d \u0027DEPARTMENT OF ENVIRONMENTA\u0027:\n        x \u003d \u0027DEPARTMENT OF ENVIRONMENTAL\u0027\n    if x \u003d\u003d \u0027CUNY KINGSBOROUGH COMMMUNI\u0027:\n        x \u003d \u0027CUNY KINGSBOROUGH COMMUNITY\u0027\n    if x \u003d\u003d \u0027DEPARTMENT OF TRANSPORTATI\u0027:\n        x \u003d \u0027DEPARTMENT OF TRANSPORTATION\u0027\n    if x \u003d\u003d \u0027OFFICE OF MANAGEMENT AND B\u0027:\n        x \u003d \u0027OFFICE OF MANAGEMENT AND BUDGET\u0027\n    if x \u003d\u003d \u0027DEPARTMENT OF HOMELESS SER\u0027:\n        x \u003d \u0027DEPARTMENT OF HOMELESS SERVICES\u0027\n    if x \u003d\u003d \u0027CUNY BRONX COMMUNITY COLLE\u0027:\n        x \u003d \u0027CUNY BRONX COMMUNITY COLLEGE\u0027\n    if x \u003d\u003d \u0027DISTRICT ATTORNEY-QUEENS C\u0027:\n        x \u003d \u0027DISTRICT ATTORNEY-QUEENS COUNTY\u0027\n    if x \u003d\u003d \u0027DEPARTMENT OF PARKS \u0026 RECR\u0027:\n        x \u003d \u0027DEPARTMENT OF PARKS \u0026 RECREATION\u0027\n    if x \u003d\u003d \u0027DISTRICT ATTORNEY-RICHMOND\u0027:\n        x \u003d \u0027DISTRICT ATTORNEY-RICHMOND COUNTY\u0027\n    if x \u003d\u003d \u0027DISTRICT ATTORNEY-KINGS CO\u0027:\n        x \u003d \"DISTRICT ATTORNEY-KINGS COUNTY\"\n    if x \u003d\u003d \u0027HOUSING PRESERVATION \u0026 DEV\u0027:\n        x \u003d \u0027HOUSING PRESERVATION \u0026 DEVELOPMENT\u0027\n    if x \u003d\u003d \u0027TRIBOROUGH BRIDGE AND TUNN\u0027:\n        x \u003d \u0027TRIBOROUGH BRIDGE AND TUNNEL\u0027\n    if x \u003d\u003d \u0027FINANCIAL INFORMATION SERV\u0027:\n        x \u003d \u0027FINANCIAL INFORMATION SERVIVES\u0027\n    if x \u003d\u003d \u0027ADMINISTRATION FOR CHILDRE\u0027:\n        x \u003d \"ADMINISTRATION FOR CHILDREN\u0027S SERVIVES\"\n    if x \u003d\u003d \u0027DEPARTMENT OF YOUTH AND CO\u0027:\n        x \u003d \u0027DEPARTMENT OF YOUTH AND COMUNITY SERVICES\u0027\n    if x \u003d\u003d \u0027TAXI AND LIMOUSINE COMMISS\u0027:\n        x \u003d \u0027TAXI AND LIMOUSINE COMMISSION\u0027\n    if x \u003d\u003d \u0027DEPARTMENT OF CONSUMER AFF\u0027:\n        x \u003d \u0027DEPARTMENT OF CONSUMER AFFAIRS\u0027\n    if x \u003d\u003d \u0027DEPARTMENT OF CITY PLANNIN\u0027:\n        x \u003d \u0027DEPARTMENT OF CITY PLANNING\u0027\n    if x \u003d\u003d \u0027CUNY HUNTER COLLEGE HIGH S\u0027:\n        x \u003d \u0027CUNY HUNTER COLLEGE HIGH SCHOOL\u0027\n    if x \u003d\u003d \u0027DISTRICT ATTORNEY-BRONX CO\u0027:\n        x \u003d \u0027DISTRICT ATTORNEY-BRONX COUNTY\u0027\n    if x \u003d\u003d \u0027DISTRICT ATTORNEY - SPECIA\u0027:\n        x \u003d \u0027DISTRICT ATTORNEY - SPECIAL AGENT\u0027\n    if x \u003d\u003d \u0027CIVILIAN COMPLAINT REVIEW\u0027:\n        x \u003d \u0027CIVILIAN COMPLAINT REVIEW BOARD\u0027\n    if x \u003d\u003d \"TEACHERS\u0027 RETIREMENT SYSTE\":\n        x \u003d \"TEACHERS\u0027 RETIREMENT SYSTEM\"\n    if x \u003d\u003d \u0027OFFICE OF EMERGENCY MANAGE\u0027:\n        x \u003d \"OFFICE OF EMERGENCY MANAGEMENT\"\n    if x \u003d\u003d \u0027DEPARTMENT OF BUSINESS SER\u0027:\n        x \u003d \"DEPARTMENT OF BUSINESS SERVICES\"\n    if x \u003d\u003d \u0027OFFICE OF PAYROLL ADMINIST\u0027:\n        x \u003d \u0027OFFICE OF PAYROLL ADMINISTRATION\u0027\n    if x \u003d\u003d \u0027CUNY COLLEGE OF STATEN ISL\u0027:\n        x \u003d \u0027CUNY COLLEGE OF STATEN ISLAND\u0027\n    if x \u003d\u003d \u0027DEPT. OF RECORDS AND INFOR\u0027:\n        x \u003d \u0027DEPT. OF RECORDS AND INFORMATION SERVICES\u0027\n    if x \u003d\u003d \u0027DEPARTMENT OF CULTURAL AFF\u0027:\n        x \u003d \u0027DEPARTMENT OF CULTURAL AFFAIRS\u0027\n    if x \u003d\u003d \u0027BUSINESS INTEGRITY COMMISS\u0027:\n        x \u003d \u0027BUSINESS INTEGRITY COMMISSION\u0027\n    if x \u003d\u003d \u0027LANDMARKS PRESERVATION COM\u0027:\n        x \u003d \u0027LANDMARKS PRESERVATION COMMISSON\u0027\n    if x \u003d\u003d \u0027PUBLIC ADMINISTRATOR NEW Y\u0027:\n        x \u003d \u0027PUBLIC ADMINISTRATOR NEW YORK CITY\u0027\n    if x \u003d\u003d \u0027COMMUNITY BOARD NO.1 BRONX\u0027:\n        x \u003d \u0027BRONX COMMUNITY BOARD #1\u0027\n    return x"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\ndef clean(x):\n    x \u003d toUpperCase(x)\n    return x"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\ndef clean_new(x):\n    x \u003d toUpperCase(x)\n    x \u003d elimateBlank(x)\n    x \u003d identical(x)\n    return x"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n####dataset1 test for Name Agency"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\ndef clean_for_dataset1(x):\n    x \u003d toUpperCase(x)\n    x \u003d elimateBlank(x)\n    x \u003d identical(x)\n    x \u003d completeTheDatas(x)\n    return x"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name1 \u003d dataset1.map(lambda x: (x[3], 1)).countByKey()\nfor key, value in agency_name1.items():\n    print(key, value)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_old1 \u003d dataset1.map(lambda x: (clean(x[3]),1)).countByKey()\nfor key, value in agency_name1.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_new1 \u003d dataset1.map(lambda x: (clean_new(x[3]),1)).countByKey()\nfor key, value in agency_name_new.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_d1 \u003d dataset1.map(lambda x: (clean_for_dataset1(x[3]),1)).countByKey()\nfor key, value in agency_name_d1.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n#count the precision for original clean and clean_new\n#we use the recall to check the percentage of the darty data and the numbers of the data we clean\narr_origin \u003d []\narr_old \u003d []\narr_new \u003d []\narr_pres \u003d []\nfor key, value in agency_name1.items():\n    arr_origin.append(key)\nfor key, value in agency_name_old1.items():\n    arr_old.append(key)\nfor key, value in agency_name_new1.items():\n    arr_new.append(key)\nfor key, value in agency_name_d1.items():\n    arr_pres.append(key)\n    \nclean_recall \u003d len(set(arr_old).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\nclean_new_recall \u003d  len(set(arr_new).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\n\nprint(\"clean_recall:\")\nprint(clean_recall)\nprint(\"clean_new_recall:\")\nprint(clean_new_recall)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n###dataset2 test for Agency Name"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name2 \u003d dataset2.map(lambda x: (x[2], 1)).countByKey()\nfor key, value in agency_name2.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_old2 \u003d dataset2.map(lambda x: (clean(x[2]),1)).countByKey()\nfor key, value in agency_name_old2.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_d2 \u003d dataset2.map(lambda x: (clean_new(x[2]),1)).countByKey()\nfor key, value in agency_name_d2.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n#count the precision for original clean and clean_new\n#we use the recall to check the percentage of the darty data and the numbers of the data we clean\n#in this case arr_new is just the same as arr_pres\narr_origin \u003d []\narr_old \u003d []\narr_new \u003d []\narr_pres \u003d []\nfor key, value in agency_name2.items():\n    arr_origin.append(key)\nfor key, value in agency_name_old2.items():\n    arr_old.append(key)\nfor key, value in agency_name_d2.items():\n    arr_new.append(key)\nfor key, value in agency_name_d2.items():\n    arr_pres.append(key)\n    \nclean_recall \u003d len(set(arr_old).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\nclean_new_recall \u003d  len(set(arr_new).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\n\nprint(\"clean_recall:\")\nprint(clean_recall)\nprint(\"clean_new_recall:\")\nprint(clean_new_recall)"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n###dataset3 test for Agency Name"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name3 \u003d dataset3.map(lambda x: (x[2],1)).countByKey()\nfor key, value in agency_name3.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_old3 \u003d dataset3.map(lambda x: (clean(x[2]),1)).countByKey()\nfor key, value in agency_name_old3.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_d3 \u003d dataset3.map(lambda x: (clean_new(x[2]),1)).countByKey()\nfor key, value in agency_name_d3.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n#count the precision for original clean and clean_new\n#we use the recall to check the percentage of the darty data and the numbers of the data we clean\n#in this case arr_new is just the same as arr_pres\narr_origin \u003d []\narr_old \u003d []\narr_new \u003d []\narr_pres \u003d []\nfor key, value in agency_name3.items():\n    arr_origin.append(key)\nfor key, value in agency_name_old3.items():\n    arr_old.append(key)\nfor key, value in agency_name_d3.items():\n    arr_new.append(key)\nfor key, value in agency_name_d3.items():\n    arr_pres.append(key)\n\nif (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres)))) \u003d\u003d 0:\n    clean_recall \u003d 1\n    celan_new_recall \u003d 1\nelse:\n    clean_recall \u003d len(set(arr_old).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\n    clean_new_recall \u003d  len(set(arr_new).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\n\nprint(\"clean_recall:\")\nprint(clean_recall)\nprint(\"clean_new_recall:\")\nprint(clean_new_recall)"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n###dataset4 test for Agency Name"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name4 \u003d dataset4.map(lambda x: (x[0],1)).countByKey()\nfor key, value in agency_name4.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_old4 \u003d dataset4.map(lambda x:  (clean(x[0]),1)).countByKey()\nfor key, value in agency_name_old4.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_d4 \u003d dataset4.map(lambda x:  (clean_new(x[0]),1)).countByKey()\nfor key, value in agency_name_d4.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n#count the precision for original clean and clean_new\n#we use the recall to check the percentage of the darty data and the numbers of the data we clean\n#in this case arr_new is just the same as arr_pres\narr_origin \u003d []\narr_old \u003d []\narr_new \u003d []\narr_pres \u003d []\nfor key, value in agency_name4.items():\n    arr_origin.append(key)\nfor key, value in agency_name_old4.items():\n    arr_old.append(key)\nfor key, value in agency_name_d4.items():\n    arr_new.append(key)\nfor key, value in agency_name_d4.items():\n    arr_pres.append(key)\n    \nclean_recall \u003d len(set(arr_old).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\nclean_new_recall \u003d  len(set(arr_new).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\n\nprint(\"clean_recall:\")\nprint(clean_recall)\nprint(\"clean_new_recall:\")\nprint(clean_new_recall)"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n###dataset5 test for Agency Name"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name5 \u003d dataset5.map(lambda x: (x[2],1)).countByKey()\nfor key, value in agency_name5.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_old5 \u003d dataset5.map(lambda x:  (clean(x[2]),1)).countByKey()\nfor key, value in agency_name_d5.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_d5 \u003d dataset5.map(lambda x:  (clean_new(x[2]),1)).countByKey()\nfor key, value in agency_name_d5.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n#count the precision for original clean and clean_new\n#we use the recall to check the percentage of the darty data and the numbers of the data we clean\n#in this case arr_new is just the same as arr_pres\narr_origin \u003d []\narr_old \u003d []\narr_new \u003d []\narr_pres \u003d []\nfor key, value in agency_name5.items():\n    arr_origin.append(key)\nfor key, value in agency_name_old5.items():\n    arr_old.append(key)\nfor key, value in agency_name_d5.items():\n    arr_new.append(key)\nfor key, value in agency_name_d5.items():\n    arr_pres.append(key)\n    \nclean_recall \u003d len(set(arr_old).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\nclean_new_recall \u003d  len(set(arr_new).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\n\nprint(\"clean_recall:\")\nprint(clean_recall)\nprint(\"clean_new_recall:\")\nprint(clean_new_recall)"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n###dataset6 test for Agency Name"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name6 \u003d dataset6.map(lambda x: (x[3],1)).countByKey()\nfor key, value in agency_name6.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_old6 \u003d dataset6.map(lambda x:  (clean(x[3]),1)).countByKey()\nfor key, value in agency_name_d6.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_d6 \u003d dataset6.map(lambda x:  (clean_new(x[3]),1)).countByKey()\nfor key, value in agency_name_d6.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n#count the precision for original clean and clean_new\n#we use the recall to check the percentage of the darty data and the numbers of the data we clean\n#in this case arr_new is just the same as arr_pres\narr_origin \u003d []\narr_old \u003d []\narr_new \u003d []\narr_pres \u003d []\nfor key, value in agency_name6.items():\n    arr_origin.append(key)\nfor key, value in agency_name_old6.items():\n    arr_old.append(key)\nfor key, value in agency_name_d6.items():\n    arr_new.append(key)\nfor key, value in agency_name_d6.items():\n    arr_pres.append(key)\n    \nclean_recall \u003d len(set(arr_old).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\nclean_new_recall \u003d  len(set(arr_new).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\n\nprint(\"clean_recall:\")\nprint(clean_recall)\nprint(\"clean_new_recall:\")\nprint(clean_new_recall)"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n###dataset7 test for Agency Name"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name7 \u003d dataset7.map(lambda x: (x[6],1)).countByKey()\nfor key, value in agency_name7.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_old7 \u003d dataset7.map(lambda x:  (clean(x[6]),1)).countByKey()\nfor key, value in agency_name_old7.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_d7 \u003d dataset7.map(lambda x:  (clean_new(x[6]),1)).countByKey()\nfor key, value in agency_name_d7.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n#count the precision for original clean and clean_new\n#we use the recall to check the percentage of the darty data and the numbers of the data we clean\n#in this case arr_new is just the same as arr_pres\narr_origin \u003d []\narr_old \u003d []\narr_new \u003d []\narr_pres \u003d []\nfor key, value in agency_name7.items():\n    arr_origin.append(key)\nfor key, value in agency_name_old7.items():\n    arr_old.append(key)\nfor key, value in agency_name_d7.items():\n    arr_new.append(key)\nfor key, value in agency_name_d7.items():\n    arr_pres.append(key)\n    \nclean_recall \u003d (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres)))) / len(set(arr_old).difference(set(arr_origin)))\nclean_new_recall \u003d  len(set(arr_new).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\n\nprint(\"clean_recall:\")\nprint(clean_recall)\nprint(\"clean_new_recall:\")\nprint(clean_new_recall)"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n###dataset8 test for Agency Name"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name8 \u003d dataset8.map(lambda x: (x[10],1)).countByKey()\nfor key, value in agency_name8.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_old8 \u003d dataset8.map(lambda x:  (clean(x[10]),1)).countByKey()\nfor key, value in agency_name_d8.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_d8 \u003d dataset8.map(lambda x:  (clean_new(x[10]),1)).countByKey()\nfor key, value in agency_name_d8.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n#count the precision for original clean and clean_new\n#we use the recall to check the percentage of the darty data and the numbers of the data we clean\n#in this case arr_new is just the same as arr_pres\narr_origin \u003d []\narr_old \u003d []\narr_new \u003d []\narr_pres \u003d []\nfor key, value in agency_name8.items():\n    arr_origin.append(key)\nfor key, value in agency_name_old8.items():\n    arr_old.append(key)\nfor key, value in agency_name_d8.items():\n    arr_new.append(key)\nfor key, value in agency_name_d8.items():\n    arr_pres.append(key)\n    \nclean_recall \u003d len(set(arr_old).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\nclean_new_recall \u003d  len(set(arr_new).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\n\nprint(\"clean_recall:\")\nprint(clean_recall)\nprint(\"clean_new_recall:\")\nprint(clean_new_recall)"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n###dataset9 test for Agency Name"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name9 \u003d dataset9.map(lambda x: (x[2],1)).countByKey()\nfor key, value in agency_name9.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_old9 \u003d dataset9.map(lambda x: (clean(x[2]),1)).countByKey()\nfor key, value in agency_name_d9.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_d9 \u003d dataset9.map(lambda x: (clean_new(x[2]),1)).countByKey()\nfor key, value in agency_name_d9.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n#count the precision for original clean and clean_new\n#we use the recall to check the percentage of the darty data and the numbers of the data we clean\n#in this case arr_new is just the same as arr_pres\narr_origin \u003d []\narr_old \u003d []\narr_new \u003d []\narr_pres \u003d []\nfor key, value in agency_name9.items():\n    arr_origin.append(key)\nfor key, value in agency_name_old9.items():\n    arr_old.append(key)\nfor key, value in agency_name_d9.items():\n    arr_new.append(key)\nfor key, value in agency_name_d9.items():\n    arr_pres.append(key)\n    \nclean_recall \u003d len(set(arr_old).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\nclean_new_recall \u003d  len(set(arr_new).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\n\nprint(\"clean_recall:\")\nprint(clean_recall)\nprint(\"clean_new_recall:\")\nprint(clean_new_recall)"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n###dataset10 test for Agency Name"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name10 \u003d dataset10.map(lambda x: (x[2],1)).countByKey()\nfor key, value in agency_name10.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_old10 \u003d dataset10.map(lambda x: (clean(x[2]),1)).countByKey()\nfor key, value in agency_name_d10.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nagency_name_d10 \u003d dataset10.map(lambda x: (clean_new(x[2]),1)).countByKey()\nfor key, value in agency_name_d10.items():\n    print(key, value)"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n#count the precision for original clean and clean_new\n#we use the recall to check the percentage of the darty data and the numbers of the data we clean\n#in this case arr_new is just the same as arr_pres\narr_origin \u003d []\narr_old \u003d []\narr_new \u003d []\narr_pres \u003d []\nfor key, value in agency_name10.items():\n    arr_origin.append(key)\nfor key, value in agency_name_old10.items():\n    arr_old.append(key)\nfor key, value in agency_name_d10.items():\n    arr_new.append(key)\nfor key, value in agency_name_d10.items():\n    arr_pres.append(key)\n    \nclean_recall \u003d len(set(arr_old).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\nclean_new_recall \u003d  len(set(arr_new).difference(set(arr_origin))) / (len(arr_pres) - len(set(arr_origin).intersection(set(arr_pres))))\n\nprint(\"clean_recall:\")\nprint(clean_recall)\nprint(\"clean_new_recall:\")\nprint(clean_new_recall)"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\narr_pres1 \u003d []\nfor key, value in agency_name_d1.items():\n    arr_pres1.append(key)\n    \narr_pres2 \u003d []\nfor key, value in agency_name_d2.items():\n    arr_pres2.append(key)\n    \narr_pres3 \u003d []\nfor key, value in agency_name_d3.items():\n    arr_pres3.append(key)\n    \narr_pres4 \u003d []\nfor key, value in agency_name_d4.items():\n    arr_pres4.append(key)\n    \narr_pres5 \u003d []\nfor key, value in agency_name_d5.items():\n    arr_pres5.append(key)\n    \narr_pres6 \u003d []\nfor key, value in agency_name_d6.items():\n    arr_pres6.append(key)\n    \narr_pres7 \u003d []\nfor key, value in agency_name_d7.items():\n    arr_pres7.append(key)\n    \narr_pres8 \u003d []\nfor key, value in agency_name_d8.items():\n    arr_pres8.append(key)\n    \narr_pres9 \u003d []\nfor key, value in agency_name_d9.items():\n    arr_pres9.append(key)\n\narr_pres10 \u003d []\nfor key, value in agency_name_d10.items():\n    arr_pres10.append(key)"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nreference_data_agency_name \u003d set(arr_pres1).union(set(arr_pres2).union(set(arr_pres3).union(set(arr_pres4).union(set(arr_pres5).union(set(arr_pres6).union(set(arr_pres7).union(set(arr_pres8).union(set(arr_pres9).union(set(arr_pres10))))))))))"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nimport pandas as pd\nfor i in reference_data_agency_name:\n    print(i)\n\ndf \u003d pd.DataFrame(reference_data_agency_name)"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nprint(df)"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n"
    }
  ]
}